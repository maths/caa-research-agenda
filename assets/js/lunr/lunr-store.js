var store = [{
        "title": "Bmjdavies",
        "excerpt":"I work in undergraduate mathematics education, focused primarily on the assessment of proof and argumentation. I am interested in novel assessment approaches of university mathematics, and in the automation of proof comprehension assessment in particular. I am also a leader in STACK development in the Mathematics Department at University College...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/BMJDavies",
        "teaser": null
      },{
        "title": "Indunils",
        "excerpt":"I am a Lecturer in Mathematics at UWE, Bristol. I am currently undertaking doctoral research work on mathematical education and computing, focusing on the use of and the development of in-house algorithmic e-assessment system (Dewis) at University of the West of England. In particular, the research is focused on developing...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/IndunilS",
        "teaser": null
      },{
        "title": "Jcmuob",
        "excerpt":"John obtained a MSci degree in Mathematical Sciences and a PhD in Applied Mathematics from the University of Birmingham. He is an associate professor at the University of Birmingham, and a visiting academic at Jinan University, China. John’s research interests include mathematical analysis, applied mathematics, and importantly in relation to...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/JCMUoB",
        "teaser": null
      },{
        "title": "Piannone65",
        "excerpt":"Paola’s research interests are the impact that summative assessment of mathematics at university has on students’ engagement with the subject. She is also interested in exploring what reasoning skills are tested by various summative assessment methods - including CAA.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/PIannone65",
        "teaser": null
      },{
        "title": "Ajpheck",
        "excerpt":"André Heck earned MSc degrees in mathematics and chemistry, and a doctoral degree in mathematics and science education. He is senior lecturer at the Mathematics department of the University of Amsterdam, mostly teaching mathematics to students in life sciences and computer science, and coordinating mathematics deficiency courses and exams. His...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/ajpheck",
        "teaser": null
      },{
        "title": "Annoshea",
        "excerpt":"Ann is a professor in the Department of Mathematics and Statistics at Maynooth University in Ireland. She conducts research on university level mathematics education and is particularly interested in the design of tasks for undergraduate mathematics.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/annoshea",
        "teaser": null
      },{
        "title": "Colinfoster77",
        "excerpt":"I am a Reader in Mathematics Education in the Mathematics Education Centre at Loughborough University, UK. I am very interested in how CAA can be used formatively to enhance students’ experiences and improve their learning of mathematics, and particularly in how this can do more than facilitate routine practice of...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/colinfoster77",
        "teaser": null
      },{
        "title": "Georgekinnear",
        "excerpt":"George has written hundreds of assessment questions in various e-assessment systems (most recently in STACK), both for his own teaching and on behalf of others. His research interests are broadly around assessment in undergraduate mathematics.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/georgekinnear",
        "teaser": null
      },{
        "title": "Ianjones",
        "excerpt":"Ian is a Reader in Educational Assessment, with a particular interest in methods based on comparative judgement. He leads on STACK development and research at Loughborough University.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/ianjones",
        "teaser": null
      },{
        "title": "Ikon625",
        "excerpt":"Igor’ Kontorovich is a Senior Lecturer in Mathematics Department at the University of Auckland, New Zealand. He is interested in understanding the processes that people go through when learning and teaching mathematics in university. In the context of this project, he is fascinating by how students learn with, from, and...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/ikon625",
        "teaser": null
      },{
        "title": "Klhender",
        "excerpt":"I have worked at UWE Bristol since 1995 holding the roles of Lecturer, Senior Lecturer, Associate Head of Department (Cluster Lead for Mathematics) and am currently an Associate Professor in Technology Enhanced Learning. I have promoted and enhanced the student learning experience in two significant ways; firstly by working with...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/klhender",
        "teaser": null
      },{
        "title": "Maryamarfaj",
        "excerpt":" ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/maryamarfaj",
        "teaser": null
      },{
        "title": "Niclaslarson",
        "excerpt":"Currently, I have some experience with comparative judgement in No More Marking. In January 2021, I will join a project aiming to develop the use of computer assessed tasks (e.g. in STACK) for the engineering programme at the University of Agder. This project will be financed by MatRIC, which is...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/niclaslarson",
        "teaser": null
      },{
        "title": "Prowlett",
        "excerpt":"Peter is a Reader at Sheffield Hallam University, where he teaches mathematics and is a researcher focused on higher education mathematics educational practice. He has been interested in e-assessment since around 2003, including as a user of e-assessment systems and as a researcher interested in how e-assessment can be used...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/prowlett",
        "teaser": null
      },{
        "title": "Samfearn",
        "excerpt":"I am Assitant Professor of Teaching in the Mathematics department and Durham University, and for the last two to three years have helped implement automated electronic assessments as a formative component of our assessment in our Undergraduate programmes. During this time I’ve written questions (primarily in STACK) for a variety...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/samfearn",
        "teaser": null
      },{
        "title": "Sangwinc",
        "excerpt":"Chris is Professor of Mathematics Education as part of the Centre for Technology Enhanced Science Education. His research interests include (i) automatic assessment of mathematics using computer algebra, and (ii) problem solving using Moore method and similar student-centred approaches. A practical outcome of this is the STACK computer aided assessment...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/sangwinc",
        "teaser": null
      },{
        "title": "Timhunt",
        "excerpt":"I am a senior software developer working on a range of educational technologies at the UK Open University. I have been a major contributor to the STACK question type, and the Moodle quiz more generally.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/timhunt",
        "teaser": null
      },{
        "title": "Timlowe",
        "excerpt":"I am currently the Director of Teaching in the School of Mathematics and Statistics at the UK Open University. My background is as an applied mathematician, but more recently I have been interested in the use of computer-based systems to support and enhance the learning of mathematics. I have led...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/timlowe",
        "teaser": null
      },{
        "title": "Wongtks",
        "excerpt":"I am interested in learning about new technologies in education and its impact on current pedagogies and best practices.  ","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/contributors/wongtks",
        "teaser": null
      },{
        "title": "Q1",
        "excerpt":"Student make mistakes for a range of reasons, from the trivial to the conceptual. We are interested in conceptual errors, so we can improve our teaching, and perhaps reveal tricky topics. We are interested in errors made interpreting questions, so we can author less ambiguously. Conceptual errors are likely to...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q1",
        "teaser": null
      },{
        "title": "Q10",
        "excerpt":"Diagnosing and responding in detail to students’ specific errors/misconceptions has become perceived as highly valuable, and e-assessment systems have features that can facilitate this. But might it be more efficient overall to avoid attempting to diagnose errors after the fact, and instead “treat” everyone by addressing known typical errors in...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q10",
        "teaser": null
      },{
        "title": "Q11",
        "excerpt":"What motivates this question? Might it be more efficient overall to avoid attempting to diagnose and instead treat everyone? In medicine we diagnose rare things but we give everyone a vaccination. The “treat all” approach is being taken up by Foster et al. (2021) in their school mathematics curriculum design...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q11",
        "teaser": null
      },{
        "title": "Q12",
        "excerpt":"Instant feedback is sometimes presented as a considerable advantage of e-assessment, though the level and quality of feedback produced is sometimes in doubt, leading to questions about the effectiveness of such feedback to promote learning. What motivates this question? E-assessment enables instant feedback on student work. Feedback on a mistake...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q12",
        "teaser": null
      },{
        "title": "Q13",
        "excerpt":"What do students do when they engage with a mathematical question presented by the e-assessment system? Do the use paper-and-pencil to make calculations, do they do that mentally, or do they use other resources? Maybe even more importantly, how do students engage with the automated feedback that they receive? Do...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q13",
        "teaser": null
      },{
        "title": "Q14",
        "excerpt":"E-assessment systems allow the possiility of randomising question parameters and offering different students different variants of questions, or indeed different question variants to the same student for repeated practice. Does such practice promote deep learning of the concepts, or does is simply promote “pattern spotting”? What motivates this question? Martin...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q14",
        "teaser": null
      },{
        "title": "Q15",
        "excerpt":"What motivates this question? How students engage with feedback and what they do next, whether it promotes positive learning behaviour, is clearly important to close the loop of assessment for learning. Yet apparently little is known about what students do when they get feedback. Do they read it and engage...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q15",
        "teaser": null
      },{
        "title": "Q16",
        "excerpt":"Success in e-assessment signals to students that they have developed the required knowledge and understanding, which may result in disengagement from further learning. However, given that e-assessment is limited, and some prefer to test procedural knowledge through e-assessment and support this with deeper learning elsewhere, might this signal be misleading...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q16",
        "teaser": null
      },{
        "title": "Q17",
        "excerpt":"This question does not specifically refer to automated assessments, so the answer is likely to depend on whether we talk about automated assessment or electronic hand-in of traditional assessment. What do students think they need to do to succeed with automated assessments? How does this compare to ‘other’ assessments which...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q17",
        "teaser": null
      },{
        "title": "Q18",
        "excerpt":"What motivates this question? In a recent JRME editorial, Cai et al. (2020) noted that “an important question for the field is how to prevent technology from reproducing or even widening the inequities in learning opportunities across groups of students” (p. 525). The aim with this question is to check...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q18",
        "teaser": null
      },{
        "title": "Q19",
        "excerpt":"What motivates this question? Peer assessment (Topping, 2009) can be attractive to (i) engage students with assessment, (ii) promote learning through students viewing one anothers’ work, (iii) promote learning through discussion about what constitutes high quality work, (iv) reduce workload on the lecturer in summative assessment contexts. There has been...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q19",
        "teaser": null
      },{
        "title": "Q2",
        "excerpt":"Does answering questions through the medium of a computer-based assignment (with the consequential need to input answers using some form of computer syntax or mathematics editor) mean students make different errors to those made on paper? Are there more, or different types of, transcription error? Can computer based assessments detect...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q2",
        "teaser": null
      },{
        "title": "Q20",
        "excerpt":"What motivates this question? Students are often encouraged by their teachers to work in groups, as they can benefit from learning from their peers. What are different ways that teachers (and students) currently use e-assessment tasks in groups? Students are observed spontaneously forming groups for mutual peer support when taking...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q20",
        "teaser": null
      },{
        "title": "Q21",
        "excerpt":"This question is about the approaches used by e-assessment task designers, particularly regarding the design of feedback. What motivates this question? For design methodology, the motivation here is to uncover different practices that may be used by task designers. For instance, detailed post-hoc analysis of student responses enabled by e-assessment...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q21",
        "teaser": null
      },{
        "title": "Q22",
        "excerpt":"It would be useful to develop a set of design principles for e-assessment. The principles could involve the mathematical type of the question (e.g. example-generation), the format of the question (e.g. multiple choice), and the type and timing of feedback. The design principles could be used to advise practitioners. What...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q22",
        "teaser": null
      },{
        "title": "Q23",
        "excerpt":"What motivates this question? When e-assessment is introduced to a course for the first time, it is often used as a replacement for existing paper-based assessments, e.g. in one case study of a department introducing computer-aided assessment to a linear algebra module, “exercise sheets were replaced by online weekly quizzes”...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q23",
        "teaser": null
      },{
        "title": "Q24",
        "excerpt":"It seems that randomised parameters, which produce different questions for students, create a barrier to plagiarism, since a friend’s answer cannot be directly copied. But is this adequate to address plagiarism? What motivates this question? The ability to generate randomised versions of questions has been described as a strength of...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q24",
        "teaser": null
      },{
        "title": "Q25",
        "excerpt":"Many e-assessment systems permit the parametrisation of questions, and hence the ability to present several variants of each question. Are such variants of value to students? What motivates this question? The use of randomised parameters in questions has been suggested to have several advantages, including: allowing students to practice the...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q25",
        "teaser": null
      },{
        "title": "Q26",
        "excerpt":"Standard advice says that distractors should be based on common errors (e.g. Gierl et al., 2017). But does this apply to numerical mathematics items? What motivates this question? Greenhow (2008) says distractors or mal-rules are “consistent but incorrect methods” used by students when answering questions. Producing plausible distractors is difficult...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q26",
        "teaser": null
      },{
        "title": "Q27",
        "excerpt":"We believe that practice is essential to learning mathematics. We create formative e-assessments to give students that practice. Can we find evidence that this really helps students learn? What motivates this question? Answering this question may help teachers know what is the most effective way to help their students learn....","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q27",
        "teaser": null
      },{
        "title": "Q28",
        "excerpt":"What motivates this question? Two case studies are relevant here: Stockholm University changed their model of the first semester of mathematics studies about 10 years ago. A simplified description is that the semester includes two courses, algebra and calculus, each of 15 credit points. The students must pass eight e-based...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q28",
        "teaser": null
      },{
        "title": "Q29",
        "excerpt":"What motivates this question? E-assessment has considerable advantages, around efficiency and effectiveness of assessment. It also has limitations, including user input and automated marking. Finally, there are grey issues - areas that it is not certain whether they are purely advantages, limitations, or a combination. For example, the issue of...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q29",
        "teaser": null
      },{
        "title": "Q3",
        "excerpt":"What motivates this question? We need to know where and when to programme targetted feedback to student responses. It may be difficult to tell whether a wrong student answer is due to misinterpretation of the question or misscalcualtion. It would be interesting to identify those errrors that persist across different...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q3",
        "teaser": null
      },{
        "title": "Q30",
        "excerpt":"There are choices to be made about the timing of e-assessments, particularly when there are multiple assessments taking place throughout a course. What impact do these different choices have on students’ learning? What motivates this question? Previous research (Uner &amp; Roediger, 2018) has investigated the impact of placing assessment questions...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q30",
        "teaser": null
      },{
        "title": "Q31",
        "excerpt":"For instance, is there a difference between performance in traditional and flipped or blended learning environments using e-assessment? What motivates this question? There is now a large body of research showing that active learning approaches are more effective than traditional lecturing (Freeman et al., 2014), including studies of mathematics teaching...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q31",
        "teaser": null
      },{
        "title": "Q32",
        "excerpt":"What motivates this question? The question is motivated by several dual-degree programmes delivered at the Jinan University – University of Birmingham Joint Institute (J-BJI), in which the majority of core mathematics modules, had all of their in-term summative assessments, delivered as e-assessments, using Möbius. At the outset, none of the...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q32",
        "teaser": null
      },{
        "title": "Q33",
        "excerpt":"What motivates this question? The expansion of e-assessment in mathematics will require the input of an increased number of teaching staff. It is important to understand the needs of individuals who are new to e-assessment to provide the necessary support and training to enable them to succeed in adopting e-assessment....","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q33",
        "teaser": null
      },{
        "title": "Q34",
        "excerpt":"What motivates this question? In formative computer-aided assessment, feedback is mostly directed toward students. It gives them information about their performance in a task and is meant to help them improve their competencies. But how can lecturers know about the use of the assessment by their students and their progression...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q34",
        "teaser": null
      },{
        "title": "Q35",
        "excerpt":"What motivates this question? Jonsson et al. (2014) have shown that the type of tasks assigned can affect students’ learning. Therefore it is reasonable to study the types of tasks assigned in university level courses, and it seems that very little work has been done in the area of online...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q35",
        "teaser": null
      },{
        "title": "Q36",
        "excerpt":"Some express doubts that e-assessment is reliable in this way, and many use e-assessment for quite low-stakes assessment as a result. What motivates this question? Writing reliable and valid questions for e-assessment is a difficult task requiring specific expertise. Additionally, there are limitations to the e-assessment format, potentially greater focus...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q36",
        "teaser": null
      },{
        "title": "Q37",
        "excerpt":"What motivates this question? Many instititions have moved to home/remote exams due to the COVID-19 pandemic, and some may (for some courses) wish to continue with such assessments longer term. How can e-assessment help to deliver appropriate assessments and overcome some of the difficulties remote exams bring? What are the...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q37",
        "teaser": null
      },{
        "title": "Q38",
        "excerpt":"What motivates this question? The features of different e-assessment systems have advanced hugely – and new systems have been introduced – since the survey by Sangwin (2013). Some recent developments include: “AI-Assisted grading” (Gradescope, 2020), where an AI system automatically clusters short written responses from different students that it judges...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q38",
        "teaser": null
      },{
        "title": "Q39",
        "excerpt":"Common approaches include typing mathematics, often using the syntax of an underlying CAS, or a menu-driven system. These can be difficult for students to learn and are not well-aligned to the process of producing mathematics offline. It may be worthwhile investigating alternative methods for input of mathematics. Such methods might...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q39",
        "teaser": null
      },{
        "title": "Q4",
        "excerpt":"Designing feedback raises questions about the degree of explicitedness that will help the student to avoid making the same error again. Then, should feedback “just” inform what one needs to do in questions of this sort, should an example be integrated? And do all these features really make a difference?...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q4",
        "teaser": null
      },{
        "title": "Q40",
        "excerpt":"Many summative assessment situations provide student with considerable freedom of expression. On the other hand, most e-assessment tools constrain students’ ability to freely express themselves, an extreme example being MCQ in which the student can only select from predefined options. It therefore seems sensible, as automatic e-assessment tools become better...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q40",
        "teaser": null
      },{
        "title": "Q41",
        "excerpt":"Does the different submission medium of computer based questions and paper based questions affect students performance? What motivates this question? Previous research has found systematic differences in performance between paper-based and online versions of the same test (Backes and Cowan, 2019). There are two main differences between computer-based and paper-based...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q41",
        "teaser": null
      },{
        "title": "Q42",
        "excerpt":"This is an overarching question, with a number of specific sub-parts. It also rather presumes that the goal of CAA is to replicate traditional processes online! What motivates this question? The motivation for this question is fundamentally conservative, i.e. a desire to replicate online traditional work. Some previous work has...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q42",
        "teaser": null
      },{
        "title": "Q43",
        "excerpt":"What motivates this question? Lawson (2002) says it is “generally accepted throughout the mathematics community that an incorrect answer can still demonstrate the achievement of some learning outcomes”. Because of this, it is normal to award students marks for their understanding of the method involved in solving a problem, even...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q43",
        "teaser": null
      },{
        "title": "Q44",
        "excerpt":"What motivates this question? Comparative judgement has been proposed and studies as a learning activity for mathematics, and in particular conceptual learning, but there is no systematic evidence as to whether and what learning takes place. How do CJ with or without justifications of the judges’ (assessors’) decision promote the...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q44",
        "teaser": null
      },{
        "title": "Q45",
        "excerpt":"What motivates this question? A new Moodle plug-in is available for CJ. This takes care of administrative issues such as how do students submit their work etc. Perhaps the question should say summative assessment. There are decisions to make and barriers to navigate when implementing comparative judgement in HE. For...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q45",
        "teaser": null
      },{
        "title": "Q46",
        "excerpt":"How to assess mathematical problem solving using e-assessment is intimately tied into how to assess mathematical problem solving more generally. Really this is a question of task-design and how we can create tasks fine-tuned to the capabilities of e-assessment tools. What motivates this question? This question is somewhat complicated by...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q46",
        "teaser": null
      },{
        "title": "Q47",
        "excerpt":"What motivates this question? This question is directed towards the computer marking of assessment, rather than the computer mediated submission of an assessment for human marking. Writing mathematics on a piece of paper, a student has a great deal of freedom in how they proceed. On an e-assessment system, however,...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q47",
        "teaser": null
      },{
        "title": "Q48",
        "excerpt":"This is rather a broad question, which has a number of aspects. What motivates this question? Immediate feedback has long been seen as one of the advantages of e-assessment, particularly when human resource for tutoring is so scares. Kluger and DeNisi (1996) provided some evidence on when feedback is and...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q48",
        "teaser": null
      },{
        "title": "Q49",
        "excerpt":"What motivates this question? Proof lies at the heart of mathematics, and is a hallmark which distinguishes mathematics from other subjects. So, from the perspective of assessment which is authentic to the discipline, it is natural to seek to assess proof. Mathematical proof may (or may not) be more constrained...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q49",
        "teaser": null
      },{
        "title": "Q5",
        "excerpt":"In formative assessments, students typically get feedback on their response; the task designer has to make many choices about the linguistic content of this feedback. What motivates this question? There is a risk of a feedback gap between the task designer and the students, who do not understand or cannot...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q5",
        "teaser": null
      },{
        "title": "Q50",
        "excerpt":"Automated theorem provers have been around for many years and recently they have been used by those mathematicians who are interested in automated checking of proofs. To the best of my knowledge, although not used in the UK, they are used in some countries in some pure math modules (e.g....","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q50",
        "teaser": null
      },{
        "title": "Q51",
        "excerpt":"What motivates this question? This question is motivated by the need to aid practitioners in developing pedagogically-robust assessment tools for their own classroom. The framework of Mejía-Ramos et al. (2017) provides a model of the types of questions that can be asked, from the perspective of paper-based tests. Bickerton and...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q51",
        "teaser": null
      },{
        "title": "Q52",
        "excerpt":"Mathematics contains a lot of symbolism which is difficult and time consuming to type. Popular solution include “pallets” of special symbols and equation editors, or mark-up such as LaTeX. Both solutions form a serious distraction not present on paper. What motivates this question? Perhaps the most significant challenge for computer...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q52",
        "teaser": null
      },{
        "title": "Q53",
        "excerpt":"Learning about concepts by developing a rich example space has been suggested as educationally valuable (e.g., Watson &amp; Mason, 2006), with e-assessment proposed as a particularly suitable mechanism for gathering and checking examples. However, there are currently few examples of this being done in practice, and little in the way...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q53",
        "teaser": null
      },{
        "title": "Q54",
        "excerpt":"Some CAA systems appear well-placed to facilitate example generation tasks, as they can make use of sophisticated computer algebra systems to check the properties of student examples and give feedback - however this relies on the properties being ones that the system can evaluate. What motivates this question? Learner-generated example...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q54",
        "teaser": null
      },{
        "title": "Q55",
        "excerpt":"What motivates this question? Students’ strategies have been studied in previous work (e.g. Iannone et al., 2011) but computer-aided assessment brings additional constraints that warrant further investigation. For instance, students may immediately be able to sketch an example with the required properties, or orally describe the relevant features, but may...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q55",
        "teaser": null
      },{
        "title": "Q6",
        "excerpt":"To make a computer to give constructive feedback to answers, and maybe to solutions, is a complex process. How can that be handled, and what difficulties appear? What motivates this question? It is a widely shared practical concern, and particularly for one of the contributors (at the University of Adger...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q6",
        "teaser": null
      },{
        "title": "Q7",
        "excerpt":"Feedback could be tailored to the student in different ways, such as by taking into account the student’s history on performance of similar tasks or performance in a task sequence prior to the current task in this sequence. What motivates this question? Feedback on e-assessment tasks is often based on...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q7",
        "teaser": null
      },{
        "title": "Q8",
        "excerpt":"What motivates this question? The motivation is a desire to replicate, as far as is possible, some of the behaviours of expert teachers, who often seek to limit their interventions to the minimum necessary (Foster, 2014), and engage students in conversations, rather than just brain-dump the whole thing at once....","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q8",
        "teaser": null
      },{
        "title": "Q9",
        "excerpt":"This question can be interpreted on two levels, based on the scale of the “set of responses”. First, the set of responses may be to a single multiple-response item (e.g. “which of the following functions are differentiable?” or “give three different examples of parabolas with no real roots”). In this...","categories": [],
        "tags": [],
        "url": "/e-assessment-research-agenda/questions/Q9",
        "teaser": null
      }]
