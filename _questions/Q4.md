---
question_code: Q4
question_num: 4
question_text: "How can content-specific features of provided feedback, for instance explanations with examples versus generic explanations, support students' learning?" 

previous_question_code: Q6

contributors: 
- ikon625
- georgekinnear

---


Designing feedback raises questions about the degree of explicitedness that will help the student to avoid making the same error again. Then, should feedback "just" inform what one needs to do in questions of this sort, should an example be integrated? And do all these features really make a difference?



## What motivates this question?

In a study using quizzes on terms from psychology, Finn et al. (2018) found that participants' performance on a later cued recall test tended to be higher when they had received "elaborated feedback" (that presented an example of the concept) rather than just the correct answer.
A recent meta-analysis, which included studies conducted in mathematics, similarly found that elaborated feedback was more effective than feedback giving the correct answer (Van der Kleij et al., 2015).

Here, the concern is about the content of the elaborated feedback --- specifically, whether it should be a generic explanation or based on a particular example. For instance, in a question about adding fractions, the feedback could describe in general terms the process ("find a common denominator", etc.) or could present a particular example.

## What might an answer look like?

It might be possible that didactical nuances of this sort do not really make a difference to students' learning. After all, appreciating well-crafted feedback requires students to engage with it thoroughly rather than just glimpse at it. Igor' team in Auckland works on this question as part of the project on how students engage with automated feedback.

The question could be approached from three perspectives: researchers', students', and teachers'.  In the first perspective,  experiments can be conducted and performance of students randomized according to different groups is compared. The second and the third perspectives may include interviews, where participants are shown different sorts of feedback and participants' reactions are explored. It might be also interesting to see how teachers and students change their opinions (or not) when they are exposed to the results of students' performance in different feedback groups.

## Related questions

* The issue of value of content-specific feedback is related to [Q13: How do students interact with an e-assessment system?]({% link _questions/Q13.md %})
* There is a detailed discussion of the relative merits of specific feedback under [Q10: Under what circumstances is diagnosing errors worth the extra effort, as compared with generally addressing errors known to be typical?]({% link _questions/Q10.md %}).

## References

<div class="reference_list" markdown="1">

Finn, B., Thomas, R., & Rawson, K. A. (2018). Learning more from feedback: Elaborating feedback with examples enhances concept learning. Learning and Instruction, 54, 104–113. <https://doi.org/10.1016/j.learninstruc.2017.08.007>

Van der Kleij, F. M., Feskens, R. C. W., & Eggen, T. J. H. M. (2015). Effects of Feedback in a Computer-Based Learning Environment on Students’ Learning Outcomes. Review of Educational Research, 85(4), 475–511. <https://doi.org/10.3102/0034654314564881>

</div>
