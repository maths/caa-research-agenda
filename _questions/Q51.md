---
question_code: Q51
question_num: 51
question_text: "What types/forms of proof-comprehension-related questions can be meaningfully assessed using currently available e-assessment platforms?" 

previous_question_code: Q30

contributors: 
- BMJDavies

---



## What motivates this question?

This question is motivated by the need to aid practitioners in developing pedagogically-robust assessment tools for their own classroom.

## What might an answer look like?

One answer to this question, related to Q43 and Q51, might focus on design principles for writing automated assessment questions in this area. Researchers might draw on the Design-based Research methodology to iteratively develop theoretical principles and practical artefacts in a cyclic process. Ruth Reynolds and Ben Davies (University College London) have proposed a workshop to this end at the 4th International STACK Conference hosted by TTK University of Applied Sciences in April 2021. 

Another answer to this question might focus on convergent validity, comparing student performance on various question formss/types to other existing measures of students' understanding (see Q28).

## Related questions

The issue of question type/form is related to task design principles, as highlighted in Q43 and Q51, and is a specific case of Q28 on the automation of assessment for proof-based mathematics more broadly. 

* [Q49: How can the assessment of proof be automated?]({% link _questions/Q49.md %})

## References

<div class="reference_list" markdown="1">

See references in [Q28](Q28) to avoid duplication.

</div>
